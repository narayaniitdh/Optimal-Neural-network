{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "# from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "# from tensorflow.keras.utils import to_categorical  # Import to_categorical from keras.utils\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense \n",
    "\n",
    "# from tensorflow.keras.regularizers import l1_l2,l1,l2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network model\n",
    "def create_model(inp_shape,num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='leaky_relu', input_shape=inp_shape))\n",
    "    model.add(Dense(32, activation='leaky_relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Define the fitness function\n",
    "def fitness_function(model, X_train, y_train, X_test, y_test, LR):\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=LR), metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=10, verbose=0)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, np.argmax(y_pred, axis=1))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for reading dataset-1\n",
    "# Load your CSV data1 using pandas\n",
    "data1 = pd.read_csv('classData.csv')\n",
    "\n",
    "# Combine the values of the first 4 columns into a new column\n",
    "data1['Combination'] = data1.apply(lambda row: ''.join(map(str, row[:4])), axis=1)\n",
    "\n",
    "# Find unique combinations and assign label numbers\n",
    "unique_combinations = data1['Combination'].unique()\n",
    "label_mapping = {combination: label for label, combination in enumerate(unique_combinations)}\n",
    "\n",
    "# Add a new column with the label numbers\n",
    "data1['Label'] = data1['Combination'].map(label_mapping)\n",
    "\n",
    "X1 = data1.iloc[:, 4:10].values  # Features\n",
    "y1 = data1.iloc[:, 11:].values  # Labels\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X1 = scaler.fit_transform(X1)\n",
    "\n",
    "# One-hot encode the labels\n",
    "# y1_encoded = to_categorical(y1, num_classes=6)\n",
    "num_classes=6\n",
    "y1_encoded = y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling and testing model for dataset-1\n",
    "\n",
    "#Splitting dataset-1 into train and test\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "input_shape1=(X_train1.shape[1],)\n",
    "num_classes=6\n",
    "# model1=configure_model(input_shape1,num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genetic Algorithm Configuration\n",
    "generations = 10\n",
    "mutation_rate = 0.1\n",
    "\n",
    "# Initialize a population of neural network models with random weights\n",
    "population_size = 10\n",
    "population = [create_model(input_shape1,num_classes) for _ in range(population_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_population(population,X_train,y_train,X_test,y_test,num_classes,input_shape,LR):\n",
    "    for generation in range(generations):\n",
    "        # Evaluate the fitness of each model in the population\n",
    "        fitness_scores = [fitness_function(model, X_train, y_train,X_test,y_test,LR) for model in population]\n",
    "        \n",
    "        # Select the top-performing models (elitism)\n",
    "        num_parents = 3\n",
    "        parents = np.argsort(fitness_scores)[-num_parents:]\n",
    "        \n",
    "        # Crossover (create new models from the selected parents)\n",
    "        new_population = [create_model(input_shape,num_classes) for _ in range(population_size)]\n",
    "        for i in range(num_parents, population_size):\n",
    "            parent1 = random.choice(parents)\n",
    "            parent2 = random.choice(parents)\n",
    "            child_weights = []\n",
    "\n",
    "            # Iterate through the layers and set the weights individually\n",
    "            for layer in range(len(population[parent1].get_weights())):\n",
    "                # Perform crossover by taking the mean of the corresponding weights\n",
    "                layer_weights = np.mean([population[parent1].get_weights()[layer], population[parent2].get_weights()[layer]], axis=0)\n",
    "                child_weights.append(layer_weights)\n",
    "\n",
    "            # Set the weights of the child model\n",
    "            new_population[i].set_weights(child_weights)\n",
    "\n",
    "    population = new_population\n",
    "\n",
    "    return population,fitness_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/step\n",
      "50/50 [==============================] - 0s 963us/step\n",
      "50/50 [==============================] - 0s 881us/step\n",
      "50/50 [==============================] - 0s 1ms/step\n",
      "50/50 [==============================] - 0s 1ms/step\n",
      "50/50 [==============================] - 0s 851us/step\n",
      "50/50 [==============================] - 0s 845us/step\n",
      "50/50 [==============================] - 0s 1ms/step\n",
      "50/50 [==============================] - 0s 957us/step\n",
      "50/50 [==============================] - 0s 955us/step\n",
      "50/50 [==============================] - 0s 1ms/step\n",
      "50/50 [==============================] - 0s 844us/step\n",
      "50/50 [==============================] - 0s 988us/step\n",
      "50/50 [==============================] - 0s 849us/step\n",
      "50/50 [==============================] - 0s 887us/step\n",
      "50/50 [==============================] - 0s 850us/step\n",
      "50/50 [==============================] - 0s 820us/step\n",
      "50/50 [==============================] - 0s 1ms/step\n",
      "50/50 [==============================] - 0s 638us/step\n",
      "50/50 [==============================] - 0s 2ms/step\n",
      "50/50 [==============================] - 0s 990us/step\n",
      "50/50 [==============================] - 0s 1ms/step\n",
      "50/50 [==============================] - 0s 883us/step\n",
      "50/50 [==============================] - 0s 1ms/step\n",
      "50/50 [==============================] - 0s 862us/step\n",
      "50/50 [==============================] - 0s 638us/step\n",
      "50/50 [==============================] - 0s 638us/step\n",
      "50/50 [==============================] - 0s 637us/step\n",
      "50/50 [==============================] - 0s 1ms/step\n",
      "50/50 [==============================] - 0s 974us/step\n",
      "50/50 [==============================] - 0s 625us/step\n",
      "50/50 [==============================] - 0s 844us/step\n",
      "50/50 [==============================] - 0s 638us/step\n",
      "50/50 [==============================] - 0s 696us/step\n",
      "50/50 [==============================] - 0s 638us/step\n",
      "50/50 [==============================] - 0s 959us/step\n",
      "50/50 [==============================] - 0s 636us/step\n",
      "50/50 [==============================] - 0s 956us/step\n",
      "50/50 [==============================] - 0s 957us/step\n",
      "50/50 [==============================] - 0s 875us/step\n",
      "50/50 [==============================] - 0s 956us/step\n",
      "50/50 [==============================] - 0s 768us/step\n",
      "50/50 [==============================] - 0s 881us/step\n",
      "50/50 [==============================] - 0s 1ms/step\n",
      "50/50 [==============================] - 0s 487us/step\n",
      "50/50 [==============================] - 0s 638us/step\n",
      "50/50 [==============================] - 0s 774us/step\n",
      "50/50 [==============================] - 0s 956us/step\n",
      "50/50 [==============================] - 0s 638us/step\n",
      "50/50 [==============================] - 0s 636us/step\n",
      "50/50 [==============================] - 0s 955us/step\n",
      "50/50 [==============================] - 0s 638us/step\n",
      "50/50 [==============================] - 0s 638us/step\n",
      "50/50 [==============================] - 0s 638us/step\n",
      "50/50 [==============================] - 0s 955us/step\n",
      "50/50 [==============================] - 0s 638us/step\n",
      "50/50 [==============================] - 0s 636us/step\n",
      "50/50 [==============================] - 0s 637us/step\n",
      "50/50 [==============================] - 0s 957us/step\n",
      "50/50 [==============================] - 0s 638us/step\n",
      "50/50 [==============================] - 0s 956us/step\n",
      "50/50 [==============================] - 0s 638us/step\n",
      "50/50 [==============================] - 0s 545us/step\n",
      "50/50 [==============================] - 0s 892us/step\n",
      "50/50 [==============================] - 0s 638us/step\n",
      "50/50 [==============================] - 0s 1ms/step\n",
      "50/50 [==============================] - 0s 774us/step\n",
      "50/50 [==============================] - 0s 625us/step\n",
      "50/50 [==============================] - 0s 766us/step\n",
      "50/50 [==============================] - 0s 741us/step\n",
      "50/50 [==============================] - 0s 638us/step\n",
      "50/50 [==============================] - 0s 636us/step\n",
      "50/50 [==============================] - 0s 957us/step\n",
      "50/50 [==============================] - 0s 585us/step\n",
      "50/50 [==============================] - 0s 920us/step\n",
      "50/50 [==============================] - 0s 958us/step\n",
      "50/50 [==============================] - 0s 957us/step\n",
      "50/50 [==============================] - 0s 882us/step\n",
      "50/50 [==============================] - 0s 2ms/step\n",
      "50/50 [==============================] - 0s 997us/step\n",
      "50/50 [==============================] - 0s 735us/step\n",
      "50/50 [==============================] - 0s 617us/step\n",
      "50/50 [==============================] - 0s 837us/step\n",
      "50/50 [==============================] - 0s 511us/step\n",
      "50/50 [==============================] - 0s 477us/step\n",
      "50/50 [==============================] - 0s 751us/step\n",
      "50/50 [==============================] - 0s 957us/step\n",
      "50/50 [==============================] - 0s 955us/step\n",
      "50/50 [==============================] - 0s 636us/step\n",
      "50/50 [==============================] - 0s 592us/step\n",
      "50/50 [==============================] - 0s 956us/step\n",
      "50/50 [==============================] - 0s 955us/step\n",
      "50/50 [==============================] - 0s 638us/step\n",
      "50/50 [==============================] - 0s 637us/step\n",
      "50/50 [==============================] - 0s 820us/step\n",
      "50/50 [==============================] - 0s 728us/step\n",
      "50/50 [==============================] - 0s 1ms/step\n",
      "50/50 [==============================] - 0s 758us/step\n",
      "50/50 [==============================] - 0s 638us/step\n",
      "50/50 [==============================] - 0s 638us/step\n",
      "Best accuracy: 0.8785759694850604\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_population1,fitness_scores1=generate_population(population,X_train1,y_train1,X_test1,y_test1,num_classes,input_shape1,0.0065)\n",
    "\n",
    "# Find the best model from the final generation\n",
    "best_model1 = final_population1[np.argmax(fitness_scores1)]\n",
    "best_accuracy1 = fitness_scores1[np.argmax(fitness_scores1)]\n",
    "print(f\"Best accuracy: {best_accuracy1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset preprocessing for dataset-2\n",
    "\n",
    "# Load your CSV data using pandas\n",
    "data2 = pd.read_csv('cwru_bearing.csv')\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Identify unique labels in the last column\n",
    "unique_labels = data2['fault'].unique()\n",
    "\n",
    "# Step 2: Create a mapping from labels to numbers\n",
    "label_to_number = {label: index for index, label in enumerate(unique_labels)}\n",
    "\n",
    "# Step 3: Replace labels with corresponding numbers\n",
    "data2['fault'] = data2['fault'].map(label_to_number)\n",
    "\n",
    "# Now, 'Y' contains numeric labels from 0-9\n",
    "\n",
    "# You can save the modified DataFrame to a new CSV file if needed\n",
    "# data2.to_csv('cwru_bearing_numeric_labels.csv', index=False)\n",
    "# Standardize the data\n",
    "\n",
    "X2 = data2.iloc[:, 0:9].values  # Features\n",
    "y2 = data2.iloc[:, 9].values  # Labels\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X2 = scaler.fit_transform(X2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling and testing model for dataset-2\n",
    "\n",
    "#Splitting dataset-1 into train and test\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "num_classes=10\n",
    "input_shape2=(X_train2.shape[1],)\n",
    "\n",
    "# model2=configure_model(input_shape2,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genetic Algorithm Configuration\n",
    "generations = 10\n",
    "mutation_rate = 0.1\n",
    "\n",
    "# Initialize a population of neural network models with random weights\n",
    "population_size = 10\n",
    "population = [create_model(input_shape2,num_classes) for _ in range(population_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 900us/step\n",
      "15/15 [==============================] - 0s 868us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 920us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 0s/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 0s/step\n",
      "15/15 [==============================] - 0s 0s/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 0s/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 928us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 849us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 0s/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 929us/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 857us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 929us/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 905us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 0s/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 0s/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 933us/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 920us/step\n",
      "15/15 [==============================] - 0s 972us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 0s/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 772us/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 991us/step\n",
      "15/15 [==============================] - 0s 633us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 0s/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 854us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 0s/step\n",
      "15/15 [==============================] - 0s 0s/step\n",
      "15/15 [==============================] - 0s 803us/step\n",
      "15/15 [==============================] - 0s 0s/step\n",
      "15/15 [==============================] - 0s 929us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 0s/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 571us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Best accuracy: 0.9652173913043478\n"
     ]
    }
   ],
   "source": [
    "final_population2,fitness_scores2=generate_population(population,X_train2,y_train2,X_test2,y_test2,num_classes,input_shape2,0.0169)\n",
    "\n",
    "# Find the best model from the final generation\n",
    "best_model2 = final_population2[np.argmax(fitness_scores2)]\n",
    "best_accuracy2 = fitness_scores2[np.argmax(fitness_scores2)]\n",
    "print(f\"Best accuracy: {best_accuracy2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_176\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_528 (Dense)           (None, 64)                448       \n",
      "                                                                 \n",
      " dense_529 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_530 (Dense)           (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2726 (10.65 KB)\n",
      "Trainable params: 2726 (10.65 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_284\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_852 (Dense)           (None, 64)                640       \n",
      "                                                                 \n",
      " dense_853 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_854 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3050 (11.91 KB)\n",
      "Trainable params: 3050 (11.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(best_model1.summary())\n",
    "print(best_model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model architecture to a JSON file\n",
    "# model_json = best_model1.to_json()\n",
    "# with open(\"model_architecture.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "\n",
    "# Save the model weights to an HDF5 file\n",
    "# best_model1.save_weights(\"model_weights1.h5\")\n",
    "best_model1\n",
    "best_model1.save(\"model1.keras\")\n",
    "best_model2.save(\"model2.keras\")\n",
    "# # Save the model architecture to a JSON file\n",
    "# model_json = best_model2.to_json()\n",
    "# with open(\"model_architecture.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "\n",
    "# # Save the model weights to an HDF5 file\n",
    "# best_model2.save_weights(\"model_weights2.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
